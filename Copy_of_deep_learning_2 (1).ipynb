{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of deep_learning_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ti9sGhemyre4"
      },
      "source": [
        "# Data Science\n",
        "\n",
        "Before starting the exercises make sure to enable the GPU\n",
        "\n",
        "\n",
        "*   Go to the runtime menu (&#8593; )\n",
        "*   Select *Change runtime type*\n",
        "*   Select GPU as *Hardware accelerator*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rR7OVW6P36N9"
      },
      "source": [
        "## Deep Learning 2 (1 hour 30 min)\n",
        "\n",
        "### Exercise 1 (10 min) -- Some more questions about Deep Learning\n",
        "\n",
        "Edit this cell to write **T** (True) or **F** (False) *before* each assertion\n",
        "\n",
        "1. **T** Bad choice of optimization parameters can cause underfitting\n",
        "1. **F** Decreasing the minibatch size helps reducing noise in the gradients\n",
        "1. **F** If a CNN is overfitting, doubling the number of filters will usually make it overfit twice more\n",
        "1. **T** The learning rate and the batch size often have an impact on generalization\n",
        "1. **F** Decrease the learning rate for the optimizer helps overcome overfitting\n",
        "1. **T** Inserting normalization layers (e.g. BatchNorm) helps overcome underfitting\n",
        "1. **F** Typical neural network architectures are over-parameterized, meaning that they have enough trainable parameters to fit arbitrary noise labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrpzZETi4AyE"
      },
      "source": [
        "### Exercise 2 (20 min) -- Gradient Descent and momentum in numpy\n",
        "\n",
        "While building a minimal  neural network (a linear model) in numpy, we define the parameters $\\theta$ as a matrix $W$ of shape `(8, 1)` and a bias vector $b$ of shape `(1,)`. You are given the functions to compute the loss and the gradient of the loss w.r.t. the parameters.\n",
        "\n",
        "1. write a function that performs gradient descent over `n_iter` steps with a given `learning rate`\n",
        "2. write a function that performs momentum gradient descent over `n_iter` steps with a given `learning rate` and `momentum`\n",
        "\n",
        "*Hint*: formula for the momentum update:\n",
        "\n",
        "$$ \\mathbf{v} \\leftarrow \\mu \\cdot \\mathbf{v} + \\nabla $$\n",
        "$$ \\mathbf{\\theta} \\leftarrow \\theta - \\eta \\cdot \\mathbf{v} $$\n",
        "\n",
        "where:\n",
        "\n",
        "- $\\theta$ is the vector of trainable parameters\n",
        "- $\\eta$ is the `learning_rate` coefficient\n",
        "- $\\mu$ is the `momentum` coefficient\n",
        "- $\\nabla$ is the gradient (usually of the loss function for the current value, in this case a random vector)\n",
        "- $\\mathbf{v}$ is the tensor of velocities and as the same shape as the parameters tensor $\\theta$. $\\mathbf{v}$ is initialized to zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMkpAOFJ8uTG"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "n_samples = 100\n",
        "n_features = 8\n",
        "\n",
        "rng = np.random.RandomState(seed=0)\n",
        "X = rng.randn(n_samples, n_features)\n",
        "w_true = rng.randn(n_features)\n",
        "b_true = rng.randn(1)\n",
        "noise = rng.randn(n_samples) / 10\n",
        "y = X @ w_true + b_true + noise"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u99ktdI35WQ"
      },
      "source": [
        "def loss(params):\n",
        "    y_pred = X @ params[0] + params[1]\n",
        "    return np.mean(0.5 * (y - y_pred) ** 2, axis=0)\n",
        "\n",
        "\n",
        "def gradients(params):\n",
        "    y_pred = X @ params[0] + params[1]\n",
        "    diff = y_pred - y\n",
        "    return [np.mean(X * diff.reshape(-1, 1), axis=0),\n",
        "            np.mean(diff, axis=0)]# Write your code here"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe729yMf4Zx-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23351b58-5962-425b-942f-4ad405c3a33e"
      },
      "source": [
        "init_params = [np.zeros(shape=(n_features,)),\n",
        "               np.zeros(shape=(1,))]\n",
        "\n",
        "loss(init_params)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.387651045016995"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuZoHJOjvE5s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTky3RiRsbXQ",
        "outputId": "15a9decd-e73f-4e3a-f588-866403c247dd"
      },
      "source": [
        "gradients(init_params)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([-1.38796564, -1.12056059, -0.35814543,  0.65666592, -1.5200169 ,\n",
              "        -0.79684241, -0.69080678, -0.08511958]), 2.114556483761852]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWVylm9s4aj_"
      },
      "source": [
        "learning_rate = 0.1\n",
        "momentum = 0.5"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyRMWUza4dB5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07ced95-5116-41bf-f286-bec933d141be"
      },
      "source": [
        "def gradient_descent(init_params, n_iter=5):\n",
        "    params = [p.copy() for p in init_params]\n",
        "    for step in range(n_iter):\n",
        "        new_gradients = gradients(params)\n",
        "        params[0] = params[0] - new_gradients[0]*learning_rate\n",
        "        params[1] = params[1] - new_gradients[1]*learning_rate\n",
        "        # write code to update the parameters with the \n",
        "        # gradients using gradient descent\n",
        "    return params\n",
        "\n",
        "\n",
        "final_params = gradient_descent(init_params, n_iter=15)\n",
        "loss(final_params)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10512056065005256"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOMuormO4eXl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19405b93-6178-4406-80a6-bd0d656df6f9"
      },
      "source": [
        "velocitity_params = [np.zeros(shape=(n_features,)),\n",
        "               np.zeros(shape=(1,))]\n",
        "\n",
        "def momentum_gradient_descent(init_params, init_velocitity,n_iter=5):\n",
        "    params = [p.copy() for p in init_params]\n",
        "    v_params = [p.copy() for p in init_velocitity]\n",
        "    for step in range(n_iter):\n",
        "        new_gradients = gradients(params)\n",
        "        v_params[0] = v_params[0]*momentum + new_gradients[0]\n",
        "        v_params[1] = v_params[1]*momentum + new_gradients[1]\n",
        "        params[0] = params[0] - v_params[0]*learning_rate\n",
        "        params[1] = params[1] - v_params[1]*learning_rate\n",
        "\n",
        "        # write code to update the parameters with the \n",
        "        # gradients using momentum gradient descent\n",
        "    return params\n",
        "\n",
        "\n",
        "final_params = momentum_gradient_descent(init_params, velocitity_params,n_iter=15)\n",
        "loss(final_params)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.008094608613871714"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZN7euDyn4haG"
      },
      "source": [
        "### Exercise 3 (30 min) -- Natural Language Classifier\n",
        "\n",
        "Alice wants to classify the topic of tweets. She is interested in knowing whether the tweet is dealing with `politics`, `technology`, `religion` or none of the 3. She supposes only one of these possibilities can happen for a given tweet.\n",
        "\n",
        "Say she has a dataset of 10K tweets with their corresponding label. \n",
        "\n",
        "##### 3.1 Describe all the preprocessing steps Alice should do before feeding the data to train the model described below:\n",
        "\n",
        "*Edit this cell and write me !*\n",
        "1-\tImporting the pandas library and loading the tweets as a dataframe\n",
        "\n",
        "2-\tRemove punctuation from text, use predefined punctiation lists such as ‘!”#$%&'()*+,-./:;?@[\\]^_`{|}~’\n",
        "\n",
        "3-\tlower case all text\n",
        "\n",
        "4-\tTokenize text, to introduce some structure either using word or sentence tokenization\n",
        "\n",
        "5-\tRemove stopwords, does not add any value to the analysis, we can use nltk library which provide a list of words considered stopwords for the english\n",
        "\n",
        "6- Tweets may also include URL, HTML tags or other rare words, we can filter them\n",
        "\n",
        "7-\tText standardization; stemming which help diminishing words to their base form\n",
        "\n",
        "8-\tLemmatizing, a more practical text standardization that preserve the meaning. Lemmatizing is dictionary based and can be slow\n",
        "\n",
        "9- transforming text data into numerical value, plenty of methods exist such as bag of word which encode each docuement on a vector with an overall vocabulary, if the word is present 1 if not 0. Other methods considers the frequency over the collection of documents such as TF-IDF\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s40-_fF4tKk"
      },
      "source": [
        "##### 3.2 Analysis of the model\n",
        "\n",
        "Add a **T** (True) or **F** (False) before each of the follwoing statements\n",
        "\n",
        "- **T** 4 is a correct number of classes for this problem\n",
        "- **T** 20000 is a suitable vocabulary size\n",
        "- **F** 5 is a suitable embedding dimension\n",
        "- **F** 50 is a suitable sequence length\n",
        "- **F** The first model only has parameters in the Dense layer\n",
        "- **T** The first model takes into account the order of the words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTPUcqHy5Cb3"
      },
      "source": [
        "##### 3.3 Write the second and third models in the `elif` statements below\n",
        "\n",
        "- model 2: based on LSTM with a sensible number of hidden units\n",
        "- model 3: based on several Convolutions1D and MaxPoolings with sensible numbers of parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8vqFQvu4f6Z"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Input, Flatten, Convolution1D, MaxPooling1D\n",
        "from tensorflow.keras.layers import GlobalAveragePooling1D, Embedding, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "MAX_NB_WORDS = 20000\n",
        "EMBEDDING_DIM = 5\n",
        "MAX_SEQUENCE_LENGTH = 50\n",
        "model_num = 2\n",
        "N_CLASSES = 4\n",
        "\n",
        "# input: a sequence of MAX_SEQUENCE_LENGTH integers\n",
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "\n",
        "embedding_layer = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=True)\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "\n",
        "if model_num == 1:\n",
        "    x = GlobalAveragePooling1D()(embedded_sequences)\n",
        "    predictions = Dense(N_CLASSES, activation='softmax')(x)\n",
        "elif model_num == 2:\n",
        "    x = LSTM(128)(embedded_sequences)\n",
        "    x = Dense(100, name=\"dense_final\")(x)\n",
        "    predictions = Dense(N_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    \n",
        "    pass\n",
        "\n",
        "elif model_num == 3:\n",
        "    x = Convolution1D(128, 5,activation='relu', name='conv1')(embedded_sequences)\n",
        "    x = MaxPooling1D()(x)\n",
        "    x = Convolution1D(128, 5,activation='relu', name='conv2')(x)\n",
        "    x = MaxPooling1D()(x)\n",
        "    x = Flatten(name=\"flatten1\")(x)\n",
        "    x = Dense(100, name=\"dense_final\")(x)\n",
        "    predictions = Dense(N_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, predictions)\n",
        "model.compile(loss=\"categorical_crossentropy\",\n",
        "              optimizer='adam', metrics=['acc'])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIWMd6mS5HJe"
      },
      "source": [
        "Use the following random input to check that you code can run without failing with randomly initialized weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA3Jejt95Hh8",
        "outputId": "7688bbda-6b0d-46a5-b977-5c4db354a6d8"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "batch_size = 3\n",
        "random_batch = np.random.randint(low=0, high=MAX_NB_WORDS,\n",
        "                                 size=(batch_size, MAX_SEQUENCE_LENGTH))\n",
        "model.predict(random_batch)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f996700fd40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.24971864, 0.25047985, 0.25000224, 0.24979931],\n",
              "       [0.24929018, 0.25098228, 0.24994725, 0.24978033],\n",
              "       [0.25053275, 0.24918959, 0.25025746, 0.2500202 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLewCn6V5RzC"
      },
      "source": [
        "##### 3.4 Using a Transformer model instead\n",
        "\n",
        "Add a **T** (True) or **F** (False) before each of the follwoing statements\n",
        "\n",
        "- **T/F** The self-attention mechanism enables to take into account the order of the words\n",
        "- **T/F** It is necessary to add a positional embedding in transformer architectures when working with sequential data\n",
        "- **T/F** It is possible to use a pre-trained architecture and fine-tune it for a classification task such as the one above\n",
        "- **T/F** Transformer architectures can be used in sequence in sequence settings such as Machine Translation\n",
        "- **T/F** The self-attention mechanism does not bring additional parameters to the transformer architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su8VAyUG5VGA"
      },
      "source": [
        "### Exercise 4 (30 min) -- Captioning\n",
        "\n",
        "##### 4.1 Consider the following image-captioning model, which takes as input an image, and produces as output a sentence describing the image.\n",
        "\n",
        "<img src=\"https://i.imgur.com/QRS2Hrj.png\" style=\"width: 600px;\" />\n",
        "\n",
        "Notes:\n",
        "- All the images in the training set are 224x224 RGB color images.\n",
        "- Each sentence in the training set is an English sentence of maximum length 20, with words indexed as integers in a vocabulary of size 1000. There are special symbols; `<s>` for start of sequence and `<eos>` for end of sequence included in the 20 words length.\n",
        "- Henri does not one-hot encode the text part of the training data: he feeds the model directly with arrays of integer values as representation for the sequences.\n",
        "- During training, we use teacher forcing, which means we pass as input both the image and the shifted output text, and predict the next word.\n",
        "- The ResNet is pre-trained on ImageNet and outputs a vector representation of each image in dimension 2048, then a linear projection projects to a dimension of 128\n",
        "- For simplicity, we add the $h$ (`img_features` in the code below) image representation to the decoder's hidden activation $h_i^{dec}$ at each time step instead of just the first one, using `RepeatVector` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWpTCaHn5QQJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten, SimpleRNN, RepeatVector, Lambda\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Embedding, Dot, Reshape, Softmax\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "base_model = ResNet50(include_top=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPP27GpC5oh7"
      },
      "source": [
        "input_img = base_model.layers[0].input\n",
        "input_text = Input(shape=(20,), dtype='int32')\n",
        "\n",
        "MAX_NB_WORDS = 1000\n",
        "EMBEDDING_DIM = 128\n",
        "SEQ_LENGTH = 20\n",
        "\n",
        "# Image features: from the pre-trained resnet\n",
        "img_features = base_model.layers[-2].output\n",
        "img_features = Dense(EMBEDDING_DIM, use_bias=False)(img_features)\n",
        "img_features = RepeatVector(SEQ_LENGTH)(img_features)\n",
        "\n",
        "# Input text embedding\n",
        "input_text = Input(shape=(SEQ_LENGTH,), dtype='int32')\n",
        "embedding_layer = Embedding(MAX_NB_WORDS, EMBEDDING_DIM,\n",
        "                            input_length=SEQ_LENGTH)\n",
        "embedded_text = embedding_layer(input_text)\n",
        "\n",
        "# Combining the two and producing the output\n",
        "rnn_input = embedded_text + img_features\n",
        "output_seq = SimpleRNN(EMBEDDING_DIM)(rnn_input)\n",
        "output_seq = Dense(MAX_NB_WORDS, activation=\"softmax\")(output_seq)\n",
        "\n",
        "model = Model([input_img, input_text], output_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6imPX8F5rqD"
      },
      "source": [
        "##### 4.2 Analysis of the model\n",
        "\n",
        "Edit this cell to add a **T** (True) or **F** (False) before each of the follwoing statements\n",
        "\n",
        "- **T/F** `base_model.layers[-2].output` has spatial dimensions\n",
        "- **T/F** After the `Dense` Layer `img_features` has spatial dimensions\n",
        "- **T/F** After the `RepeatVector` Layer, `img_features` has sequential dimensions\n",
        "- **T/F** The linear projection has parameters\n",
        "- **T/F** It is possible to fine tune the ResNet50 parameters when training the RNN\n",
        "- **T/F** The hidden-to-hidden parameter matrix of the RNN has a shape of (128, 1000)\n",
        "- **T/F** it is possible to add an attention mechanism to focus on specific part of the picture\n",
        "- **T/F** This model is a conditional language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16LE4ZcR6N-E"
      },
      "source": [
        "##### 4.3 Train / Test time\n",
        "\n",
        "At train time, we use both the image and a shifted version of the expected target sequence fed as input for the RNN decoder (\"teacher forcing\").\n",
        "\n",
        "Edit this cell to add a **T** (True) or **F** (False) before each of the follwoing statements\n",
        "\n",
        "- **T/F** At test time, it is possible to use this same strategy (input both the image and the shifted output)\n",
        "- **T/F** It is possible that we just capture the language structure, and barely take into account the image\n",
        "- **T/F** At test time, we can decode the first word, then the second given the first, etc... (greedy decoding)\n",
        "- **T/F** A beam search would probably improve results over a greedy decoding\n",
        "- **T/F** For shorter sequences, there will be a stronger vanishing gradients problem\n",
        "- **T/F** Replacing the RNN with an LSTM will help generalization, but will make the training more difficult\n",
        "- **T/F** Replacing the basic RNN model (while preserving its 128 hidden dimension) by a LSTM would reduce the number of parameters"
      ]
    }
  ]
}